{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import tensorflow \n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "matplotlib.use(\"Agg\")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get list of directories__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories\n",
    "    # names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "\n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images: 3018\n",
      "training labels: 3018\n",
      "first image address in train data hcaptcha_dataset/train/motorcycle/1650230255278_2.jpg\n",
      "shape of the image: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "imagePaths = getListOfFiles(\"hcaptcha_dataset/train/\")\n",
    "#imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))## Folder structure: datasets --> sub-folders with labels name\n",
    "#print(imagePaths)\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "c = 0 \n",
    "for image in imagePaths:\n",
    "\n",
    "    lable = os.path.split(os.path.split(image)[0])[1]\n",
    "    labels.append(lable)\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.resize(img, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "    #img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #print(img)\n",
    "    data.append(img)\n",
    "    \n",
    "print(\"training images:\",len(data))\n",
    "print(\"training labels:\",len(labels))\n",
    "print(\"first image address in train data\",imagePaths[0])\n",
    "print(\"shape of the image:\",data[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  2414\n",
      "Shape of training data:  (2414, 32, 32, 3)\n",
      "Validation data:  604\n",
      "validation data Shape:  (604, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "                                                  labels, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Training data: \",len(trainX))\n",
    "print(\"Shape of training data: \",trainX.shape)\n",
    "print(\"Validation data: \",len(testX))\n",
    "print(\"validation data Shape: \",testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         vertical_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a baseline Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create baseline model with above specifications\n",
    "model = tf.keras.Sequential([\n",
    "                                       tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        tf.keras.layers.Dense(1024,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(256,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(64,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 177ms/step - loss: 1.9002 - accuracy: 0.2157 - val_loss: 1.7907 - val_accuracy: 0.2980\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 3s 152ms/step - loss: 1.7107 - accuracy: 0.3626 - val_loss: 1.5497 - val_accuracy: 0.3907\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 1.5503 - accuracy: 0.3746 - val_loss: 1.4386 - val_accuracy: 0.4238\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 1.4656 - accuracy: 0.4331 - val_loss: 1.3716 - val_accuracy: 0.4603\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 3s 175ms/step - loss: 1.3784 - accuracy: 0.4873 - val_loss: 1.3197 - val_accuracy: 0.4884\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 3s 151ms/step - loss: 1.3326 - accuracy: 0.4899 - val_loss: 1.3009 - val_accuracy: 0.4570\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 1.3021 - accuracy: 0.4965 - val_loss: 1.2114 - val_accuracy: 0.5298\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 1.2462 - accuracy: 0.5317 - val_loss: 1.1861 - val_accuracy: 0.5497\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 3s 137ms/step - loss: 1.2161 - accuracy: 0.5304 - val_loss: 1.1583 - val_accuracy: 0.5348\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 3s 146ms/step - loss: 1.1917 - accuracy: 0.5472 - val_loss: 1.1111 - val_accuracy: 0.5861\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 1.1466 - accuracy: 0.5630 - val_loss: 1.0806 - val_accuracy: 0.5960\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 1.1298 - accuracy: 0.5722 - val_loss: 1.0517 - val_accuracy: 0.6308\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 3s 147ms/step - loss: 1.1692 - accuracy: 0.5634 - val_loss: 1.0825 - val_accuracy: 0.5778\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 1.1496 - accuracy: 0.5687 - val_loss: 1.0963 - val_accuracy: 0.6026\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 3s 150ms/step - loss: 1.1077 - accuracy: 0.5792 - val_loss: 1.0128 - val_accuracy: 0.6308\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 3s 151ms/step - loss: 1.0657 - accuracy: 0.6094 - val_loss: 0.9738 - val_accuracy: 0.6391\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 1.0625 - accuracy: 0.6002 - val_loss: 0.9462 - val_accuracy: 0.6589\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 3s 151ms/step - loss: 1.0718 - accuracy: 0.6024 - val_loss: 0.9725 - val_accuracy: 0.6424\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 3s 154ms/step - loss: 1.0230 - accuracy: 0.6220 - val_loss: 0.9233 - val_accuracy: 0.6424\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 3s 141ms/step - loss: 1.0110 - accuracy: 0.6207 - val_loss: 0.9197 - val_accuracy: 0.6573\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 3s 143ms/step - loss: 1.0200 - accuracy: 0.6290 - val_loss: 0.9106 - val_accuracy: 0.6490\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 3s 143ms/step - loss: 0.9832 - accuracy: 0.6299 - val_loss: 0.8871 - val_accuracy: 0.6755\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 1.0047 - accuracy: 0.6207 - val_loss: 0.9500 - val_accuracy: 0.6341\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 3s 148ms/step - loss: 0.9943 - accuracy: 0.6374 - val_loss: 0.9314 - val_accuracy: 0.6556\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 3s 149ms/step - loss: 0.9968 - accuracy: 0.6282 - val_loss: 0.9022 - val_accuracy: 0.6623\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 3s 146ms/step - loss: 0.9735 - accuracy: 0.6509 - val_loss: 0.9208 - val_accuracy: 0.6573\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 3s 146ms/step - loss: 0.9571 - accuracy: 0.6654 - val_loss: 0.8817 - val_accuracy: 0.6672\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 3s 150ms/step - loss: 0.9588 - accuracy: 0.6566 - val_loss: 0.8423 - val_accuracy: 0.6772\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.9431 - accuracy: 0.6514 - val_loss: 0.9075 - val_accuracy: 0.6722\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 3s 154ms/step - loss: 0.9702 - accuracy: 0.6382 - val_loss: 0.8546 - val_accuracy: 0.6772\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 3,426,055\n",
      "Trainable params: 3,426,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with number of layers and neurons per layer to increase the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 178ms/step - loss: 1.9188 - accuracy: 0.1951 - val_loss: 1.8518 - val_accuracy: 0.3411\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 3s 151ms/step - loss: 1.8253 - accuracy: 0.2397 - val_loss: 1.7400 - val_accuracy: 0.3791\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 3s 157ms/step - loss: 1.7098 - accuracy: 0.3718 - val_loss: 1.6050 - val_accuracy: 0.3543\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 4s 211ms/step - loss: 1.5880 - accuracy: 0.3762 - val_loss: 1.4957 - val_accuracy: 0.3940\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 1.5233 - accuracy: 0.4003 - val_loss: 1.4707 - val_accuracy: 0.3874\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 3s 139ms/step - loss: 1.4699 - accuracy: 0.4090 - val_loss: 1.4157 - val_accuracy: 0.4089\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.4525 - accuracy: 0.4484 - val_loss: 1.3819 - val_accuracy: 0.4735\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.4163 - accuracy: 0.4816 - val_loss: 1.3476 - val_accuracy: 0.4834\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.3709 - accuracy: 0.4781 - val_loss: 1.3320 - val_accuracy: 0.4702\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 3s 144ms/step - loss: 1.3297 - accuracy: 0.4821 - val_loss: 1.2688 - val_accuracy: 0.4901\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.2987 - accuracy: 0.5109 - val_loss: 1.2910 - val_accuracy: 0.4702\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.2521 - accuracy: 0.5289 - val_loss: 1.2267 - val_accuracy: 0.4950\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.2488 - accuracy: 0.5254 - val_loss: 1.2530 - val_accuracy: 0.4983\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 1.2161 - accuracy: 0.5446 - val_loss: 1.1864 - val_accuracy: 0.5199\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.1964 - accuracy: 0.5459 - val_loss: 1.1584 - val_accuracy: 0.5381\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.1870 - accuracy: 0.5525 - val_loss: 1.1168 - val_accuracy: 0.5795\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1636 - accuracy: 0.5595 - val_loss: 1.1183 - val_accuracy: 0.5695\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1597 - accuracy: 0.5547 - val_loss: 1.0920 - val_accuracy: 0.5662\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.1301 - accuracy: 0.5796 - val_loss: 1.0976 - val_accuracy: 0.5778\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 1.0995 - accuracy: 0.6019 - val_loss: 1.0576 - val_accuracy: 0.5762\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1004 - accuracy: 0.5906 - val_loss: 1.0326 - val_accuracy: 0.6142\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0811 - accuracy: 0.5927 - val_loss: 1.0329 - val_accuracy: 0.6043\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.0558 - accuracy: 0.6028 - val_loss: 1.0362 - val_accuracy: 0.6159\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0615 - accuracy: 0.6089 - val_loss: 1.0650 - val_accuracy: 0.6109\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.0534 - accuracy: 0.6089 - val_loss: 1.0165 - val_accuracy: 0.6142\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 3s 142ms/step - loss: 1.0676 - accuracy: 0.6002 - val_loss: 1.0196 - val_accuracy: 0.6126\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 3s 160ms/step - loss: 1.0249 - accuracy: 0.6189 - val_loss: 1.0052 - val_accuracy: 0.6192\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 3s 144ms/step - loss: 1.0445 - accuracy: 0.6177 - val_loss: 0.9399 - val_accuracy: 0.6540\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0243 - accuracy: 0.6242 - val_loss: 0.9344 - val_accuracy: 0.6490\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 0.9969 - accuracy: 0.6330 - val_loss: 0.9508 - val_accuracy: 0.6440\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3146752   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 3,426,055\n",
      "Trainable params: 3,426,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "                                       tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        tf.keras.layers.Dense(256,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(128,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(64,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_1.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_1.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 158ms/step - loss: 1.8904 - accuracy: 0.2262 - val_loss: 1.8014 - val_accuracy: 0.3675\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.7893 - accuracy: 0.3390 - val_loss: 1.7089 - val_accuracy: 0.3659\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.6929 - accuracy: 0.3508 - val_loss: 1.5990 - val_accuracy: 0.3642\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.6069 - accuracy: 0.3915 - val_loss: 1.5110 - val_accuracy: 0.4404\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.5249 - accuracy: 0.4160 - val_loss: 1.4406 - val_accuracy: 0.4487\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.4795 - accuracy: 0.4484 - val_loss: 1.4032 - val_accuracy: 0.5232\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 1.4249 - accuracy: 0.4694 - val_loss: 1.3598 - val_accuracy: 0.4719\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 126ms/step - loss: 1.3767 - accuracy: 0.5017 - val_loss: 1.3336 - val_accuracy: 0.4536\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.3342 - accuracy: 0.4978 - val_loss: 1.2504 - val_accuracy: 0.5199\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.3023 - accuracy: 0.5052 - val_loss: 1.2237 - val_accuracy: 0.5447\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.2622 - accuracy: 0.5326 - val_loss: 1.1866 - val_accuracy: 0.5546\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.2364 - accuracy: 0.5468 - val_loss: 1.1502 - val_accuracy: 0.5993\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.2157 - accuracy: 0.5608 - val_loss: 1.1425 - val_accuracy: 0.5811\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.1836 - accuracy: 0.5639 - val_loss: 1.1119 - val_accuracy: 0.6192\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1730 - accuracy: 0.5682 - val_loss: 1.0916 - val_accuracy: 0.6026\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.1553 - accuracy: 0.5862 - val_loss: 1.0716 - val_accuracy: 0.6258\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1503 - accuracy: 0.5774 - val_loss: 1.0482 - val_accuracy: 0.6159\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.1110 - accuracy: 0.6037 - val_loss: 1.0271 - val_accuracy: 0.6308\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.0935 - accuracy: 0.5958 - val_loss: 1.0064 - val_accuracy: 0.6391\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.0802 - accuracy: 0.6054 - val_loss: 1.0237 - val_accuracy: 0.6142\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0759 - accuracy: 0.6098 - val_loss: 1.0179 - val_accuracy: 0.6258\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 1.0604 - accuracy: 0.6146 - val_loss: 0.9536 - val_accuracy: 0.6623\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 3s 163ms/step - loss: 1.0404 - accuracy: 0.6194 - val_loss: 0.9578 - val_accuracy: 0.6391\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0406 - accuracy: 0.6155 - val_loss: 0.9867 - val_accuracy: 0.6275\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0471 - accuracy: 0.6220 - val_loss: 0.9173 - val_accuracy: 0.6672\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0141 - accuracy: 0.6277 - val_loss: 0.9222 - val_accuracy: 0.6672\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 0.9999 - accuracy: 0.6369 - val_loss: 0.9138 - val_accuracy: 0.6689\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 0.9993 - accuracy: 0.6352 - val_loss: 0.9332 - val_accuracy: 0.6639\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 0.9794 - accuracy: 0.6444 - val_loss: 0.8928 - val_accuracy: 0.6656\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 0.9894 - accuracy: 0.6492 - val_loss: 0.8801 - val_accuracy: 0.6788\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 402,055\n",
      "Trainable params: 402,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "                                       tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                       tf.keras.layers.Dense(128,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(64,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_2.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 150ms/step - loss: 1.8622 - accuracy: 0.2594 - val_loss: 1.6353 - val_accuracy: 0.4056\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.6082 - accuracy: 0.4449 - val_loss: 1.5003 - val_accuracy: 0.4487\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.4999 - accuracy: 0.4703 - val_loss: 1.3856 - val_accuracy: 0.4868\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.4344 - accuracy: 0.4812 - val_loss: 1.3225 - val_accuracy: 0.5132\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.3784 - accuracy: 0.5000 - val_loss: 1.2948 - val_accuracy: 0.5778\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 1.3442 - accuracy: 0.5157 - val_loss: 1.2868 - val_accuracy: 0.5596\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.3146 - accuracy: 0.5317 - val_loss: 1.2167 - val_accuracy: 0.5646\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.2827 - accuracy: 0.5494 - val_loss: 1.1943 - val_accuracy: 0.5546\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 1.2411 - accuracy: 0.5516 - val_loss: 1.1667 - val_accuracy: 0.5828\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.2380 - accuracy: 0.5590 - val_loss: 1.1360 - val_accuracy: 0.6308\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 3s 138ms/step - loss: 1.2057 - accuracy: 0.5731 - val_loss: 1.1145 - val_accuracy: 0.6523\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1921 - accuracy: 0.5827 - val_loss: 1.1205 - val_accuracy: 0.6076\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1740 - accuracy: 0.5792 - val_loss: 1.0783 - val_accuracy: 0.6540\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1547 - accuracy: 0.5881 - val_loss: 1.0992 - val_accuracy: 0.6159\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1769 - accuracy: 0.5704 - val_loss: 1.0596 - val_accuracy: 0.6325\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1489 - accuracy: 0.5801 - val_loss: 1.0699 - val_accuracy: 0.6192\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1313 - accuracy: 0.5997 - val_loss: 1.0316 - val_accuracy: 0.6573\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 3s 159ms/step - loss: 1.1163 - accuracy: 0.6076 - val_loss: 1.0272 - val_accuracy: 0.6507\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 3s 143ms/step - loss: 1.1160 - accuracy: 0.5941 - val_loss: 1.0248 - val_accuracy: 0.6589\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1151 - accuracy: 0.6006 - val_loss: 1.0059 - val_accuracy: 0.6606\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1012 - accuracy: 0.6045 - val_loss: 1.0035 - val_accuracy: 0.6556\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 3s 139ms/step - loss: 1.0791 - accuracy: 0.6251 - val_loss: 1.0044 - val_accuracy: 0.6474\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 126ms/step - loss: 1.0780 - accuracy: 0.6155 - val_loss: 0.9873 - val_accuracy: 0.6358\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.0718 - accuracy: 0.6220 - val_loss: 0.9731 - val_accuracy: 0.6540\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 124ms/step - loss: 1.0542 - accuracy: 0.6203 - val_loss: 0.9907 - val_accuracy: 0.6540\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 1.0499 - accuracy: 0.6194 - val_loss: 0.9735 - val_accuracy: 0.6440\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 2s 124ms/step - loss: 1.0535 - accuracy: 0.6190 - val_loss: 0.9481 - val_accuracy: 0.6705\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.0608 - accuracy: 0.6168 - val_loss: 0.9579 - val_accuracy: 0.6639\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0328 - accuracy: 0.6242 - val_loss: 0.9768 - val_accuracy: 0.6440\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0143 - accuracy: 0.6352 - val_loss: 0.9388 - val_accuracy: 0.6573\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 197,127\n",
      "Trainable params: 197,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        \n",
    "                                      \n",
    "                                       tf.keras.layers.Dense(64,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_3.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_3.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 157ms/step - loss: 2.1121 - accuracy: 0.2126 - val_loss: 1.5989 - val_accuracy: 0.3974\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.5562 - accuracy: 0.3858 - val_loss: 1.3380 - val_accuracy: 0.5248\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 121ms/step - loss: 1.3959 - accuracy: 0.4714 - val_loss: 1.2550 - val_accuracy: 0.5695\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 122ms/step - loss: 1.3429 - accuracy: 0.4913 - val_loss: 1.2754 - val_accuracy: 0.4950\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 3s 158ms/step - loss: 1.3204 - accuracy: 0.5149 - val_loss: 1.1634 - val_accuracy: 0.6175\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 3s 153ms/step - loss: 1.2766 - accuracy: 0.5271 - val_loss: 1.1508 - val_accuracy: 0.6010\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 120ms/step - loss: 1.2352 - accuracy: 0.5402 - val_loss: 1.1153 - val_accuracy: 0.6076\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.2192 - accuracy: 0.5451 - val_loss: 1.0871 - val_accuracy: 0.6275\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1847 - accuracy: 0.5665 - val_loss: 1.0433 - val_accuracy: 0.6672\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.1967 - accuracy: 0.5599 - val_loss: 1.0804 - val_accuracy: 0.6341\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.1831 - accuracy: 0.5757 - val_loss: 1.0366 - val_accuracy: 0.6407\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 1.1830 - accuracy: 0.5591 - val_loss: 1.0314 - val_accuracy: 0.6258\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1501 - accuracy: 0.5783 - val_loss: 0.9894 - val_accuracy: 0.6738\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 1.1483 - accuracy: 0.5722 - val_loss: 0.9908 - val_accuracy: 0.6705\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1158 - accuracy: 0.5792 - val_loss: 1.0272 - val_accuracy: 0.6424\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1444 - accuracy: 0.5770 - val_loss: 0.9731 - val_accuracy: 0.6854\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.1312 - accuracy: 0.5980 - val_loss: 1.0484 - val_accuracy: 0.6060\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.1188 - accuracy: 0.5853 - val_loss: 1.0010 - val_accuracy: 0.6440\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1063 - accuracy: 0.6037 - val_loss: 0.9938 - val_accuracy: 0.6705\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.1058 - accuracy: 0.6010 - val_loss: 0.9914 - val_accuracy: 0.6391\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0854 - accuracy: 0.6203 - val_loss: 1.0080 - val_accuracy: 0.6391\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0999 - accuracy: 0.5901 - val_loss: 0.9496 - val_accuracy: 0.6788\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 126ms/step - loss: 1.1008 - accuracy: 0.5984 - val_loss: 0.9357 - val_accuracy: 0.6970\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.0949 - accuracy: 0.5958 - val_loss: 0.9329 - val_accuracy: 0.6937\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0966 - accuracy: 0.5871 - val_loss: 0.9551 - val_accuracy: 0.6937\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1055 - accuracy: 0.6002 - val_loss: 0.9452 - val_accuracy: 0.6722\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.1078 - accuracy: 0.5941 - val_loss: 0.9284 - val_accuracy: 0.6970\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.0890 - accuracy: 0.6059 - val_loss: 0.9615 - val_accuracy: 0.6838\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.0881 - accuracy: 0.6129 - val_loss: 0.9520 - val_accuracy: 0.6921\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0948 - accuracy: 0.6024 - val_loss: 0.9145 - val_accuracy: 0.7070\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 21511     \n",
      "=================================================================\n",
      "Total params: 21,511\n",
      "Trainable params: 21,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        \n",
    "                                      \n",
    "                                       \n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_4.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_4.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 170ms/step - loss: 2.0237 - accuracy: 0.1934 - val_loss: 1.9344 - val_accuracy: 0.2136\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.9282 - accuracy: 0.1912 - val_loss: 1.8892 - val_accuracy: 0.2136\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.8977 - accuracy: 0.1995 - val_loss: 1.8732 - val_accuracy: 0.2268\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.8855 - accuracy: 0.2148 - val_loss: 1.8569 - val_accuracy: 0.2268\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.8668 - accuracy: 0.2139 - val_loss: 1.8240 - val_accuracy: 0.2268\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.8231 - accuracy: 0.2668 - val_loss: 1.7629 - val_accuracy: 0.3526\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.7666 - accuracy: 0.3364 - val_loss: 1.7010 - val_accuracy: 0.3642\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.7058 - accuracy: 0.3451 - val_loss: 1.6626 - val_accuracy: 0.3543\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.6606 - accuracy: 0.3447 - val_loss: 1.6002 - val_accuracy: 0.3609\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.6174 - accuracy: 0.3526 - val_loss: 1.5381 - val_accuracy: 0.3675\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.5845 - accuracy: 0.3482 - val_loss: 1.5098 - val_accuracy: 0.3692\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.5733 - accuracy: 0.3460 - val_loss: 1.5009 - val_accuracy: 0.3659\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.5516 - accuracy: 0.3482 - val_loss: 1.5246 - val_accuracy: 0.3576\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.5549 - accuracy: 0.3705 - val_loss: 1.5308 - val_accuracy: 0.3510\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 138ms/step - loss: 1.5372 - accuracy: 0.3517 - val_loss: 1.4997 - val_accuracy: 0.3659\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.5275 - accuracy: 0.3578 - val_loss: 1.4531 - val_accuracy: 0.4056\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 137ms/step - loss: 1.5075 - accuracy: 0.3941 - val_loss: 1.4474 - val_accuracy: 0.3957\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.5171 - accuracy: 0.3832 - val_loss: 1.4485 - val_accuracy: 0.3957\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.4855 - accuracy: 0.4051 - val_loss: 1.4459 - val_accuracy: 0.3924\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.4835 - accuracy: 0.3990 - val_loss: 1.4401 - val_accuracy: 0.3858\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.4833 - accuracy: 0.3919 - val_loss: 1.4317 - val_accuracy: 0.4040\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.4836 - accuracy: 0.3963 - val_loss: 1.4744 - val_accuracy: 0.3940\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 123ms/step - loss: 1.4781 - accuracy: 0.4046 - val_loss: 1.4238 - val_accuracy: 0.4139\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.4567 - accuracy: 0.3955 - val_loss: 1.4277 - val_accuracy: 0.4073\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.4609 - accuracy: 0.4049 - val_loss: 1.4315 - val_accuracy: 0.3940\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 1.4595 - accuracy: 0.3955 - val_loss: 1.4207 - val_accuracy: 0.3924\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 3s 151ms/step - loss: 1.4634 - accuracy: 0.4029 - val_loss: 1.4704 - val_accuracy: 0.3742\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.4572 - accuracy: 0.4068 - val_loss: 1.4159 - val_accuracy: 0.3957\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.4446 - accuracy: 0.4090 - val_loss: 1.4136 - val_accuracy: 0.3957\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.4420 - accuracy: 0.4029 - val_loss: 1.4125 - val_accuracy: 0.3924\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 830,567\n",
      "Trainable params: 830,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        tf.keras.layers.Dense(256,activation='sigmoid'),\n",
    "                                        tf.keras.layers.Dense(128,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(64,activation='sigmoid'), \n",
    "                                       tf.keras.layers.Dense(32,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(16,activation='sigmoid'),\n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_5.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_5.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Changing activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 4s 164ms/step - loss: 1.7821 - accuracy: 0.2528 - val_loss: 1.4746 - val_accuracy: 0.3990\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.4982 - accuracy: 0.4077 - val_loss: 1.4019 - val_accuracy: 0.4437\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.3993 - accuracy: 0.4589 - val_loss: 1.3938 - val_accuracy: 0.4321\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.3853 - accuracy: 0.4707 - val_loss: 1.3088 - val_accuracy: 0.5116\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.3637 - accuracy: 0.4703 - val_loss: 1.2314 - val_accuracy: 0.5199\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.2632 - accuracy: 0.5219 - val_loss: 1.2118 - val_accuracy: 0.5629\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.2281 - accuracy: 0.5359 - val_loss: 1.1585 - val_accuracy: 0.5381\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 139ms/step - loss: 1.1904 - accuracy: 0.5459 - val_loss: 1.1684 - val_accuracy: 0.5596\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.1729 - accuracy: 0.5521 - val_loss: 1.0959 - val_accuracy: 0.6060\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1560 - accuracy: 0.5696 - val_loss: 1.1092 - val_accuracy: 0.5679\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.1114 - accuracy: 0.5844 - val_loss: 1.0825 - val_accuracy: 0.6076\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1220 - accuracy: 0.5766 - val_loss: 1.0572 - val_accuracy: 0.6556\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.1024 - accuracy: 0.5831 - val_loss: 1.0625 - val_accuracy: 0.5927\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 136ms/step - loss: 1.1039 - accuracy: 0.5857 - val_loss: 1.0590 - val_accuracy: 0.6126\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.0696 - accuracy: 0.5967 - val_loss: 1.0448 - val_accuracy: 0.6126\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.1348 - accuracy: 0.5704 - val_loss: 1.1467 - val_accuracy: 0.5579\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.1248 - accuracy: 0.5744 - val_loss: 0.9555 - val_accuracy: 0.6540\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.0150 - accuracy: 0.6229 - val_loss: 0.9915 - val_accuracy: 0.6341\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 3s 152ms/step - loss: 1.0310 - accuracy: 0.6168 - val_loss: 1.0908 - val_accuracy: 0.5695\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 1.0351 - accuracy: 0.6115 - val_loss: 0.9640 - val_accuracy: 0.6523\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 3s 140ms/step - loss: 1.0396 - accuracy: 0.6094 - val_loss: 0.9591 - val_accuracy: 0.6589\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 3s 142ms/step - loss: 1.0118 - accuracy: 0.6190 - val_loss: 0.9259 - val_accuracy: 0.6606\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 0.9825 - accuracy: 0.6360 - val_loss: 0.9211 - val_accuracy: 0.6623\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 0.9688 - accuracy: 0.6365 - val_loss: 0.9223 - val_accuracy: 0.6656\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 0.9929 - accuracy: 0.6356 - val_loss: 0.9062 - val_accuracy: 0.6672\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 0.9364 - accuracy: 0.6549 - val_loss: 0.9063 - val_accuracy: 0.6705\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 0.9446 - accuracy: 0.6528 - val_loss: 0.9486 - val_accuracy: 0.6523\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 3s 138ms/step - loss: 0.9518 - accuracy: 0.6426 - val_loss: 0.8867 - val_accuracy: 0.6805\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 0.9414 - accuracy: 0.6430 - val_loss: 0.9804 - val_accuracy: 0.6209\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 3s 138ms/step - loss: 0.9595 - accuracy: 0.6277 - val_loss: 0.8917 - val_accuracy: 0.6639\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 830,567\n",
      "Trainable params: 830,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        tf.keras.layers.Dense(256,activation='relu'),\n",
    "                                        tf.keras.layers.Dense(128,activation='relu'),\n",
    "                                       tf.keras.layers.Dense(64,activation='relu'), \n",
    "                                       tf.keras.layers.Dense(32,activation='relu'),\n",
    "                                       tf.keras.layers.Dense(16,activation='relu'),\n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_6.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_6.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18/18 [==============================] - 3s 157ms/step - loss: 1.8833 - accuracy: 0.2983 - val_loss: 1.5453 - val_accuracy: 0.3692\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 2s 135ms/step - loss: 1.5010 - accuracy: 0.3924 - val_loss: 1.3921 - val_accuracy: 0.4421\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 1.3812 - accuracy: 0.4899 - val_loss: 1.3232 - val_accuracy: 0.5083\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 2s 134ms/step - loss: 1.3438 - accuracy: 0.4887 - val_loss: 1.2677 - val_accuracy: 0.4669\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.3074 - accuracy: 0.5017 - val_loss: 1.2029 - val_accuracy: 0.5414\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 3s 140ms/step - loss: 1.2370 - accuracy: 0.5267 - val_loss: 1.1284 - val_accuracy: 0.5662\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 2s 126ms/step - loss: 1.1827 - accuracy: 0.5604 - val_loss: 1.1483 - val_accuracy: 0.5911\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 2s 124ms/step - loss: 1.1609 - accuracy: 0.5617 - val_loss: 1.1075 - val_accuracy: 0.5861\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 1.1511 - accuracy: 0.5722 - val_loss: 1.0937 - val_accuracy: 0.6126\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 2s 125ms/step - loss: 1.1397 - accuracy: 0.5831 - val_loss: 1.0272 - val_accuracy: 0.6258\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 2s 138ms/step - loss: 1.1000 - accuracy: 0.5941 - val_loss: 1.0356 - val_accuracy: 0.5977\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 1.0797 - accuracy: 0.6111 - val_loss: 1.0329 - val_accuracy: 0.6209\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 1.1042 - accuracy: 0.5907 - val_loss: 0.9843 - val_accuracy: 0.6474\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0636 - accuracy: 0.6190 - val_loss: 0.9544 - val_accuracy: 0.6507\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 3s 165ms/step - loss: 1.0406 - accuracy: 0.6168 - val_loss: 1.0048 - val_accuracy: 0.6175\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 3s 156ms/step - loss: 1.0384 - accuracy: 0.6164 - val_loss: 0.9706 - val_accuracy: 0.6556\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 2s 125ms/step - loss: 1.0074 - accuracy: 0.6369 - val_loss: 0.9097 - val_accuracy: 0.6821\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 2s 129ms/step - loss: 1.0493 - accuracy: 0.6067 - val_loss: 0.9543 - val_accuracy: 0.6540\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 2s 132ms/step - loss: 1.0631 - accuracy: 0.6094 - val_loss: 0.9504 - val_accuracy: 0.6424\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 2s 130ms/step - loss: 1.0044 - accuracy: 0.6299 - val_loss: 0.8822 - val_accuracy: 0.6871\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 2s 122ms/step - loss: 0.9734 - accuracy: 0.6671 - val_loss: 0.9223 - val_accuracy: 0.6772\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 2s 125ms/step - loss: 1.0001 - accuracy: 0.6382 - val_loss: 0.8585 - val_accuracy: 0.6954\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 0.9663 - accuracy: 0.6579 - val_loss: 0.8458 - val_accuracy: 0.7003\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 0.9979 - accuracy: 0.6273 - val_loss: 0.8998 - val_accuracy: 0.6805\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 2s 126ms/step - loss: 1.0049 - accuracy: 0.6345 - val_loss: 0.9477 - val_accuracy: 0.6424\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 2s 128ms/step - loss: 0.9763 - accuracy: 0.6391 - val_loss: 0.8791 - val_accuracy: 0.6821\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 0.9580 - accuracy: 0.6636 - val_loss: 0.8519 - val_accuracy: 0.6921\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 2s 138ms/step - loss: 1.0003 - accuracy: 0.6352 - val_loss: 0.8819 - val_accuracy: 0.6954\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 2s 127ms/step - loss: 0.9611 - accuracy: 0.6645 - val_loss: 0.8874 - val_accuracy: 0.6871\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 2s 133ms/step - loss: 0.9789 - accuracy: 0.6448 - val_loss: 0.8683 - val_accuracy: 0.7136\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 402,055\n",
      "Trainable params: 402,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "                                        \n",
    "                                        tf.keras.layers.Dense(128,activation='tanh'),\n",
    "                                       tf.keras.layers.Dense(64,activation='tanh'), \n",
    "                                      \n",
    "                                       tf.keras.layers.Dense(7,activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model_7.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "H=model_7.fit(x=aug.flow(trainX, trainY, batch_size=128),\n",
    "              validation_data=(testX, testY), steps_per_epoch=len(trainX) // 128,\n",
    "              epochs=30, verbose=1)\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Experiment with regularization techniques: Early stopping, Dropout rate, L1 for sparse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Flatten(input_shape=(32,32,3)))\n",
    "model_drop.add(Dropout(0.1))\n",
    "model_drop.add(Dense(1024, activation='relu'))\n",
    "model_drop.add(Dense(256, activation='relu'))\n",
    "model_drop.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 4s 88ms/step - loss: 2.2470 - accuracy: 0.3036 - val_loss: 1.4059 - val_accuracy: 0.4570\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 1.3980 - accuracy: 0.4606 - val_loss: 1.2417 - val_accuracy: 0.5149\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.2871 - accuracy: 0.5116 - val_loss: 1.2425 - val_accuracy: 0.5315\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.2353 - accuracy: 0.5232 - val_loss: 1.1230 - val_accuracy: 0.5844\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.1783 - accuracy: 0.5584 - val_loss: 1.0003 - val_accuracy: 0.6358\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 3s 82ms/step - loss: 1.1490 - accuracy: 0.5671 - val_loss: 0.9891 - val_accuracy: 0.6474\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 1.1060 - accuracy: 0.5907 - val_loss: 1.0169 - val_accuracy: 0.6457\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 1.0464 - accuracy: 0.6060 - val_loss: 1.0781 - val_accuracy: 0.6126\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 1.1091 - accuracy: 0.5920 - val_loss: 1.0128 - val_accuracy: 0.6391\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 1.0403 - accuracy: 0.6056 - val_loss: 0.9008 - val_accuracy: 0.6805\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 1.0409 - accuracy: 0.6069 - val_loss: 0.8712 - val_accuracy: 0.7003\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 4s 98ms/step - loss: 1.0252 - accuracy: 0.6226 - val_loss: 0.8502 - val_accuracy: 0.6838\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 1.0062 - accuracy: 0.6292 - val_loss: 0.8296 - val_accuracy: 0.7070\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.9832 - accuracy: 0.6379 - val_loss: 0.9319 - val_accuracy: 0.6705\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 1.0047 - accuracy: 0.6309 - val_loss: 0.8302 - val_accuracy: 0.6871\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 3s 82ms/step - loss: 1.0225 - accuracy: 0.6114 - val_loss: 0.9585 - val_accuracy: 0.6242\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 3s 79ms/step - loss: 0.9894 - accuracy: 0.6239 - val_loss: 0.8229 - val_accuracy: 0.7053\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 0.9500 - accuracy: 0.6591 - val_loss: 0.8039 - val_accuracy: 0.6954\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 3s 85ms/step - loss: 0.9183 - accuracy: 0.6607 - val_loss: 0.8446 - val_accuracy: 0.7053\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.9319 - accuracy: 0.6512 - val_loss: 0.8109 - val_accuracy: 0.7219\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.9533 - accuracy: 0.6495 - val_loss: 0.8486 - val_accuracy: 0.6805\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.9061 - accuracy: 0.6665 - val_loss: 0.7719 - val_accuracy: 0.7235\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.9017 - accuracy: 0.6798 - val_loss: 0.9237 - val_accuracy: 0.6805\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.9349 - accuracy: 0.6454 - val_loss: 0.7919 - val_accuracy: 0.7119\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 0.8975 - accuracy: 0.6740 - val_loss: 0.7779 - val_accuracy: 0.7185\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.8865 - accuracy: 0.6781 - val_loss: 0.7354 - val_accuracy: 0.7401\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.8730 - accuracy: 0.6885 - val_loss: 0.7767 - val_accuracy: 0.7235\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 3s 85ms/step - loss: 0.8834 - accuracy: 0.6752 - val_loss: 0.8229 - val_accuracy: 0.7185\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.8667 - accuracy: 0.6848 - val_loss: 0.7439 - val_accuracy: 0.7450\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.8788 - accuracy: 0.6827 - val_loss: 0.7158 - val_accuracy: 0.7334\n"
     ]
    }
   ],
   "source": [
    "H_drop=model_drop.fit(x=aug.flow(trainX, trainY, batch_size=64),\n",
    "              validation_data=(testX, testY), \n",
    "              epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(H.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) L1  for sparse model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L1 = Sequential()\n",
    "\n",
    "model_L1.add(Flatten(input_shape=(32,32,3)))\n",
    "model_L1.add(Dense(1024, activation='relu',kernel_regularizer=regularizers.l1(0.0000001)))\n",
    "model_L1.add(Dense(256, activation='relu'))\n",
    "model_L1.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L1.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 5s 113ms/step - loss: 2.3343 - accuracy: 0.3049 - val_loss: 1.4008 - val_accuracy: 0.4603\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 1.3593 - accuracy: 0.4751 - val_loss: 1.3743 - val_accuracy: 0.4735\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 4s 112ms/step - loss: 1.3939 - accuracy: 0.4635 - val_loss: 1.1480 - val_accuracy: 0.5662\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 1.2287 - accuracy: 0.5348 - val_loss: 1.0608 - val_accuracy: 0.6192\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.2119 - accuracy: 0.5597 - val_loss: 1.1330 - val_accuracy: 0.5546\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 1.1465 - accuracy: 0.5684 - val_loss: 1.0425 - val_accuracy: 0.6258\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 1.1337 - accuracy: 0.5771 - val_loss: 0.9748 - val_accuracy: 0.6523\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 1.1373 - accuracy: 0.5833 - val_loss: 1.0868 - val_accuracy: 0.6010\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.0974 - accuracy: 0.5973 - val_loss: 0.9972 - val_accuracy: 0.6192\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 1.0917 - accuracy: 0.5849 - val_loss: 0.9187 - val_accuracy: 0.6705\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.0582 - accuracy: 0.6060 - val_loss: 1.0336 - val_accuracy: 0.6407\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 1.0487 - accuracy: 0.6106 - val_loss: 0.9557 - val_accuracy: 0.6854\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 1.0177 - accuracy: 0.6284 - val_loss: 0.9141 - val_accuracy: 0.6970\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.9922 - accuracy: 0.6330 - val_loss: 0.8440 - val_accuracy: 0.6970\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 1.0123 - accuracy: 0.6359 - val_loss: 0.8498 - val_accuracy: 0.6871\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.9790 - accuracy: 0.6384 - val_loss: 0.9340 - val_accuracy: 0.6606\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.9872 - accuracy: 0.6338 - val_loss: 0.8538 - val_accuracy: 0.7334\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 1.0217 - accuracy: 0.6205 - val_loss: 0.8479 - val_accuracy: 0.7003\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.9309 - accuracy: 0.6574 - val_loss: 0.8680 - val_accuracy: 0.6887\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.9184 - accuracy: 0.6491 - val_loss: 0.7826 - val_accuracy: 0.7053\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 4s 98ms/step - loss: 0.9617 - accuracy: 0.6574 - val_loss: 0.8385 - val_accuracy: 0.7268\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 0.9366 - accuracy: 0.6466 - val_loss: 0.7611 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.8930 - accuracy: 0.6794 - val_loss: 0.7556 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.8713 - accuracy: 0.6906 - val_loss: 0.7390 - val_accuracy: 0.7401\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.8660 - accuracy: 0.6976 - val_loss: 0.7461 - val_accuracy: 0.7301\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.9085 - accuracy: 0.6723 - val_loss: 0.7505 - val_accuracy: 0.7450\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 0.8134 - accuracy: 0.7092 - val_loss: 0.7237 - val_accuracy: 0.7550\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.8987 - accuracy: 0.6694 - val_loss: 0.7466 - val_accuracy: 0.7517\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.8398 - accuracy: 0.7005 - val_loss: 0.7405 - val_accuracy: 0.7401\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.8070 - accuracy: 0.7196 - val_loss: 0.6690 - val_accuracy: 0.7649\n"
     ]
    }
   ],
   "source": [
    "H=model_L1.fit(x=aug.flow(trainX, trainY, batch_size=64),\n",
    "              validation_data=(testX, testY), \n",
    "              epochs=30,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(H.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stoppping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_er = Sequential()\n",
    "\n",
    "model_er.add(Flatten(input_shape=(32,32,3)))\n",
    "model_er.add(Dense(1024, activation='relu',kernel_regularizer=regularizers.l1(0.0000001)))\n",
    "model_er.add(Dense(256, activation='relu'))\n",
    "model_er.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 6s 126ms/step - loss: 2.2334 - accuracy: 0.3177 - val_loss: 1.5057 - val_accuracy: 0.4156\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.4366 - accuracy: 0.4557 - val_loss: 1.3908 - val_accuracy: 0.4371\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 4s 101ms/step - loss: 1.2954 - accuracy: 0.5124 - val_loss: 1.1391 - val_accuracy: 0.5811\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 4s 102ms/step - loss: 1.2356 - accuracy: 0.5240 - val_loss: 1.1682 - val_accuracy: 0.5662\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 1.1631 - accuracy: 0.5530 - val_loss: 1.0733 - val_accuracy: 0.5927\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 1.1897 - accuracy: 0.5613 - val_loss: 1.0808 - val_accuracy: 0.6043\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 4s 113ms/step - loss: 1.1862 - accuracy: 0.5555 - val_loss: 0.9826 - val_accuracy: 0.6374\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.1063 - accuracy: 0.5949 - val_loss: 0.9895 - val_accuracy: 0.6225\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 1.1031 - accuracy: 0.5862 - val_loss: 0.9792 - val_accuracy: 0.6474\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 1.1023 - accuracy: 0.5878 - val_loss: 0.9618 - val_accuracy: 0.6573\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 4s 104ms/step - loss: 1.0369 - accuracy: 0.6272 - val_loss: 0.9361 - val_accuracy: 0.6589\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 1.0051 - accuracy: 0.6388 - val_loss: 0.8952 - val_accuracy: 0.6904\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.9830 - accuracy: 0.6429 - val_loss: 0.8910 - val_accuracy: 0.6755\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.0627 - accuracy: 0.6015 - val_loss: 1.0468 - val_accuracy: 0.5911\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 1.0194 - accuracy: 0.6363 - val_loss: 0.8717 - val_accuracy: 0.6871\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.9868 - accuracy: 0.6483 - val_loss: 0.8834 - val_accuracy: 0.6656\n"
     ]
    }
   ],
   "source": [
    "model_er.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model_er.fit(x=aug.flow(trainX, trainY,batch_size=64), epochs=30, validation_data=(testX, testY)\n",
    " , callbacks = [EarlyStopping(monitor='val_accuracy', patience=4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images: 746\n",
      "test labels: 746\n",
      "first image address in test data hcaptcha_dataset/test/airplane/1650246217769_16.jpg\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "imagePaths = getListOfFiles(\"hcaptcha_dataset/test/\")\n",
    "#imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))## Folder structure: datasets --> sub-folders with labels name\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "c = 0 ## to see the progress\n",
    "for image in imagePaths:\n",
    "\n",
    "    lable = os.path.split(os.path.split(image)[0])[1]\n",
    "    labels.append(lable)\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.resize(img, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "    #img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #print(img)\n",
    "    data.append(img)\n",
    "    \n",
    "print(\"test images:\",len(data))\n",
    "print(\"test labels:\",len(labels))\n",
    "print(\"first image address in test data\",imagePaths[0])\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") \n",
    "labels = np.array(labels)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=model_final.predict(data)\n",
    "y_preds = probs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'predictions': y_preds.tolist() })\n",
    "submission.to_csv(\"my_submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=pd.read_csv(\"my_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
